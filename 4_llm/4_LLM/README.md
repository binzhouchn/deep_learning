# 大模型LLM

## 1. 大模型介绍



## 2. 大模型推理加速(理论与实战，以MiniCPM为例)

[LLM大模型推理加速实战：vllm、fastllm与llama.cpp使用指南](https://cloud.baidu.com/article/3262596)<br>
[MiniCPM llama.cpp、ollama、fastllm、mlx_lm推理](https://github.com/OpenBMB/MiniCPM/tree/main?tab=readme-ov-file)<br>
[ollama模型存放位置](https://zhuanlan.zhihu.com/p/687099148)<br>

```
默认情况下, ollama run命令下载的models存放在如下目录中:

macOS: ~/.ollama/models
linux: /usr/share/ollama/.ollama/models
windows: C:\Users\<username>\.ollama\models
```

